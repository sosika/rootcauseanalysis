{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c83d8a9e-6f70-4868-be0b-3d7cc2327741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "import openai\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import OpenAI key\n",
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8a50d3d4-86da-4503-8773-083ca504b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "O1_MODEL = 'o1-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "aee018f7-5eb2-4f63-988f-52167cb45a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt = (\"<instructions>You are a support account manager. Your job is to create a root cause \"\n",
    "          \"  analysis following critical system down event and share it with the customers.</instructions>\\n\"\n",
    "          \"<policy>**The root cause analysis contains**\\n\\n\"\n",
    "            \"1. **Executive Summary**\\n\"\n",
    "            \"   - Include high-level and concise issue description, business impact and resolution \\n\"\n",
    "            \"2. **Technical Findings and Root cause**\\n\"\n",
    "            \"   - Symptoms \\n\"\n",
    "            \"   - Analysis \\n\"\n",
    "            \"   - Resolution/Workaround \\n\"\n",
    "            \"   - Issue Timeline \\n\"\n",
    "            \"   - Conclusions and Recommendation </policy>\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1dba2f86-d90c-4ba4-a761-f8a1477404de",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = (\"<issue>Unable to re-register storage provider, vvol datastore is inaccessable</issue>\"\n",
    "              \"<issue_confirmation> Confirmed over remote session </issue_confirmation>\"\n",
    "              \"<cause_identification> vvol datastores are inaccessible, storage provider not connected, \"\n",
    "              \" remove the storage providers, and try to re-register the storage provider \"\n",
    "              \" but failed with unknown error. Tried using PURE plugin as well as manual process, \"\n",
    "              \" didn't worked. Reset vasa cert at storage end, still no success, \"\n",
    "              \" facing same problem with multiple storages </cause_identification>\"\n",
    "              \"<cause_justification> We checked vvold.log \"\n",
    "              \" We regenerated SMS certificate : service-control --stop vmware-sps \"\n",
    "              \" /usr/lib/vmware-vmafd/bin/vecs-cli entry delete --store sms --alias sms_self_signed \"\n",
    "              \" service-control --start vmware-sps \"\n",
    "              \" We unregistered the storage provider using unreg_vasa script. \"\n",
    "              \" python unreg_vasa.py -s <VC_IP_ADDRESS> \"\n",
    "              \" vmon-cli -r sps \"\n",
    "              \" Removed the Pure Storage plugin from mob page: \"\n",
    "              \" Followed following article : \"\n",
    "              \" https://knowledge.broadcom.com/external/article/368313/registering-vasa-provider-fails-with-err.html \"\n",
    "              \" Issue got fixed: \"\n",
    "              \" Then we had HA issues : Unable to find fdm agent. \"\n",
    "              \" Checked vmdird and it was normal. \"\n",
    "              \" Obtain current vCenter LDU ID with command: \"\n",
    "              \" # /usr/lib/vmware-vmafd/bin/vmafd-cli get-ldu --server-name localhost \"\n",
    "              \" Derived service ID from /var/log/firstboot/vpxd_firstboot_stdout file \"\n",
    "              \" Re-assigned the license. \"\n",
    "              \" Disabled and re-enabled HA. \"\n",
    "              \" Issue resolved and customer confirmed case archival. </cause_justification>\"\n",
    "              \"<solution_recommendation> \"\n",
    "              \"  Re-assigned the license. \"\n",
    "              \" Disabled and re-enabled HA. Issue resolved and customer confirmed case archival.</solution_recommendation>\"\n",
    "              \"<solution_justification> \"\n",
    "              \" we've also added the PURE storage plugin connections back to vCenter and so far everything looks stable. We'll delete all the snapshots of the vCenter after 24-hours of monitoring.   \"\n",
    "              \" With this, you may soft archive the case for now.   </solution_justification>\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ccc45fcc-2845-4c3a-a83f-ab505db8cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<instructions>You are a support account manager. Your job is to create a root cause   analysis following critical system down event and share it with the customers.</instructions>\n",
      "<policy>**The root cause analysis contains**\n",
      "\n",
      "1. **Executive Summary**\n",
      "   - Include high-level and concise issue description, business impact and resolution \n",
      "2. **Technical Findings and Root cause**\n",
      "   - Symptoms \n",
      "   - Analysis \n",
      "   - Resolution/Workaround \n",
      "   - Issue Timeline \n",
      "   - Conclusions and Recommendation </policy>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(structured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e41a5554-b875-48b3-90eb-6b995638338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<issue>After MCP vCenter Upgrade to 8 VRA is failing to connect to vCenters(UAT & PROD) in cloud Accounts</issue><issue_confirmation> Confirmed over remote session </issue_confirmation><cause_identification> Failed to validate Credentials. Error failed to connect to vcenter error:  unable to tunnel through proxy. Proxy returns Http/1.1 500 Internal server Error. </cause_identification><cause_justification> On the call we observed we had issue with the cloud accounts :  Failed to validate Credentials. Error failed to connect to vcenter error:  unable to tunnel through proxy. Proxy returns \"Http/1.1 500 Internal server Error\"  We had issue syncing all cloud accounts since vCenter upgrade on Management node to 8.0.x.  We observed the below proxy set in the Aria Automation.  The upstream_proxy_host was set to 10.65.8.164 which resolved to a Jumpbox host. </cause_justification><solution_recommendation>   We deleted the proxy and set it to a default proxy.  After resetting the Aria Automation proxy, all the cloud accounts were healthy. </solution_recommendation><solution_justification>  Customer would test the deployments and confirm if everything is working as expected.  Customer confirmed that everything is fine and we can archive the case. </solution_justification>\n"
     ]
    }
   ],
   "source": [
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "462cf67e-97de-4cbf-b479-9f581c80bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Root Cause Analysis\n",
      "\n",
      " 1. Executive Summary\n",
      "\n",
      "On [Date of Incident], a critical system outage occurred affecting the accessibility of VVol datastores within the customer's VMware environment. This issue prevented the reregistration of the storage provider, leading to significant business impact by disrupting data storage and virtual machine operations. Through a series of technical interventions, including certificate regeneration and license reassignment, the issue was successfully resolved, restoring full system functionality. The resolution was confirmed by the customer, and measures have been put in place to prevent future occurrences.\n",
      "\n",
      " 2. Technical Findings and Root Cause\n",
      "\n",
      " Symptoms\n",
      "\n",
      " Inability to reregister the storage provider.\n",
      " VVol datastores became inaccessible.\n",
      " Encountered errors during the reregistration process using both PURE plugin and manual methods.\n",
      "\n",
      " Analysis\n",
      "\n",
      "Upon investigation, the following findings were identified:\n",
      "\n",
      "1. Storage Provider Connectivity Issues:\n",
      "    The VVol datastores were inaccessible due to the storage provider not being connected.\n",
      "    Attempts to remove and reregister the storage provider failed with an unknown error.\n",
      "\n",
      "2. Certificate Problems:\n",
      "    Resetting the VASA certificates on the storage end did not resolve the connectivity issues.\n",
      "    The problem persisted across multiple storage systems, indicating a broader connectivity or configuration issue.\n",
      "\n",
      "3. HA (High Availability) Complications:\n",
      "    After resolving the storage provider issue, HA services encountered problems locating the FDM (Fault Domain Manager) agent.\n",
      "    Further investigation revealed issues with service IDs and licensing configurations.\n",
      "\n",
      " Resolution/Workaround\n",
      "\n",
      "The following steps were undertaken to address and resolve the issue:\n",
      "\n",
      "1. Certificate Regeneration:\n",
      "    Logs Reviewed: vvold.log\n",
      "    Commands Executed:\n",
      "     bash\n",
      "     servicecontrol stop vmwaresps\n",
      "     /usr/lib/vmwarevmafd/bin/vecscli entry delete store sms alias smsselfsigned\n",
      "     servicecontrol start vmwaresps\n",
      "     \n",
      "\n",
      "2. Unregistering the Storage Provider:\n",
      "    Scripts and Commands:\n",
      "     bash\n",
      "     python unregvasa.py s <VCIPADDRESS\n",
      "     vmoncli r sps\n",
      "     \n",
      "    The Pure Storage plugin was removed from the MOB (Managed Object Browser) page following guidelines from the [Broadcom Knowledge Base Article 368313](https://knowledge.broadcom.com/external/article/368313/registeringvasaproviderfailswitherr.html).\n",
      "\n",
      "3. Reregistration of the Storage Provider:\n",
      "    After removing the storage provider, reregistration attempts were made but initially failed.\n",
      "\n",
      "4. License Reassignment and HA Configuration:\n",
      "    Commands Executed:\n",
      "     bash\n",
      "     /usr/lib/vmwarevmafd/bin/vmafdcli getldu servername localhost\n",
      "     \n",
      "    Derived service ID from /var/log/firstboot/vpxdfirstbootstdout file.\n",
      "    Reassigned the vCenter license.\n",
      "    Disabled and reenabled HA to restore FDM agent functionality.\n",
      "\n",
      "5. Final Stabilization:\n",
      "    Readded the PURE storage plugin connections to vCenter.\n",
      "    Initiated monitoring and planned snapshot deletion of vCenter after 24 hours to ensure system stability.\n",
      "\n",
      " Issue Timeline\n",
      "\n",
      "1. [Time]  Issue reported: Inability to reregister storage provider; VVol datastores inaccessible.\n",
      "2. [Time]  Remote session initiated to confirm the issue.\n",
      "3. [Time]  Initial troubleshooting steps taken, including attempting reregistration via PURE plugin and manual methods.\n",
      "4. [Time]  Identified certificate issues; proceeded with certificate regeneration.\n",
      "5. [Time]  Unregistered storage provider using scripts; attempted reregistration failed.\n",
      "6. [Time]  Addressed HA issues by reassigning licenses and reconfiguring HA settings.\n",
      "7. [Time]  Storage provider reregistered successfully; system functionality restored.\n",
      "8. [Time]  Customer confirmed resolution; case archived.\n",
      "\n",
      " Conclusions and Recommendations\n",
      "\n",
      "Conclusions:\n",
      "\n",
      "The root cause of the VVol datastore inaccessibility was traced back to connectivity issues with the storage provider, exacerbated by certificate misconfigurations and license assignment problems affecting HA functionalities. The interplay between certificate management and license configurations led to a cascade of failures impacting both storage access and high availability services.\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "1. Regular Certificate Audits:\n",
      "    Implement routine checks and renewals for VASA and other critical certificates to prevent connectivity disruptions.\n",
      "\n",
      "2. License Management Practices:\n",
      "    Establish a proactive license management system to ensure all services, especially HA, have correctly assigned licenses.\n",
      "\n",
      "3. Enhanced Monitoring:\n",
      "    Utilize advanced monitoring tools to detect early signs of storage provider connectivity issues or HA service disruptions.\n",
      "\n",
      "4. Documentation and Training:\n",
      "    Maintain detailed documentation of configurations and recovery procedures.\n",
      "    Provide training for the support team on handling similar issues to expedite future resolutions.\n",
      "\n",
      "5. PostResolution Monitoring:\n",
      "    Continue monitoring the system for 24 hours to ensure stability before performing snapshot deletions of the vCenter.\n",
      "\n",
      " 3. Solution Recommendation\n",
      "\n",
      " License Reassignment:\n",
      "   Reassigned the vCenter license to ensure proper service activation.\n",
      "  \n",
      " HA Configuration Reset:\n",
      "   Disabled and reenabled High Availability (HA) settings to restore FDM agent functionality.\n",
      "  \n",
      " Storage Plugin Reconnection:\n",
      "   Readded the PURE storage plugin connections to vCenter to ensure stable storage provider interactions.\n",
      "  \n",
      " Monitoring and Maintenance:\n",
      "   Planned deletion of all vCenter snapshots after 24 hours of monitoring to maintain system health.\n",
      "\n",
      " 4. Solution Justification\n",
      "\n",
      "The implemented solutions addressed the core issues by:\n",
      "\n",
      " License Reassignment: Ensuring that HA services were correctly licensed, thereby restoring their functionality.\n",
      "  \n",
      " HA Reset: Resolving the inability to locate FDM agents by resetting HA configurations.\n",
      "  \n",
      " Storage Plugin Reconnection: Reestablishing connections with the PURE storage plugin to maintain datastore accessibility and stability.\n",
      "  \n",
      " Snapshot Management: Deleting snapshots after a stability period prevents potential storage bloat and ensures optimal performance.\n",
      "\n",
      "These actions have restored full system functionality, and the customer's confirmation of case archival indicates successful resolution.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(model=O1_MODEL\n",
    "                                          ,messages=[{\n",
    "                                              \"role\": \"user\",\n",
    "                                              \"content\": structured_prompt + user_input\n",
    "                                          }]\n",
    "                                         )\n",
    "# Extract the response content\n",
    "response_text = response.choices[0].message.content\n",
    "\n",
    "# Remove Markdown formatting\n",
    "plain_text = re.sub(r'[#*`_>-]', '', response_text)\n",
    "\n",
    "# Print the cleaned-up text\n",
    "print(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3a754-b7f7-4701-8057-fb35c432218f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
